{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Pandas settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# CONFIG\n",
    "RAW_DATA_PATH = \"../data/raw/dataset_GTS_TRANSACTION_raw.csv\"\n",
    "CLEAN_DATA_PATH = \"../data/dataset_economy_clean.csv\"\n",
    "\n",
    "print(\"[+] Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "if os.path.exists(RAW_DATA_PATH):\n",
    "    df = pd.read_csv(RAW_DATA_PATH)\n",
    "    print(f\"[+] Loaded {len(df)} transactions.\")\n",
    "else:\n",
    "    print(f\"[-] File not found: {RAW_DATA_PATH}. Run download_data.ipynb first.\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "if not df.empty:\n",
    "    # JSON EXPANSION\n",
    "    def clean_json(x):\n",
    "        if isinstance(x, dict): return x\n",
    "        try:\n",
    "            return json.loads(x)\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "\n",
    "    df['context_data'] = df['context_data'].apply(clean_json)\n",
    "    df_context = pd.json_normalize(df['context_data'])\n",
    "\n",
    "    # Remove duplicated columns\n",
    "    cols_to_drop = df_context.columns.intersection(df.columns)\n",
    "    if not cols_to_drop.empty:\n",
    "        df_context = df_context.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Join\n",
    "    df_final = df.join(df_context).drop(columns=['context_data'])\n",
    "\n",
    "    print(\"[+] JSON expanded successfully.\")\n",
    "    display(df_final.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING (Economy Logic)\n",
    "\n",
    "if not df_final.empty:\n",
    "    # A. Parse Description (Pokemon vs Items)\n",
    "    # Examples: \"Honedge Lvl1\", \"Diamond\", \"Iron Ingot x64\" (Hypothetical)\n",
    "\n",
    "    def parse_description(row):\n",
    "        desc = str(row.get('description', ''))\n",
    "        itype = row.get('itemType', 'ITEM')\n",
    "\n",
    "        product_name = desc\n",
    "        level = 0\n",
    "        quantity = 1\n",
    "\n",
    "        if itype == 'POKEMON':\n",
    "            # Regex for \"Species LvlX\"\n",
    "            match = re.search(r'(.+)\\s+Lvl(\\d+)', desc)\n",
    "            if match:\n",
    "                product_name = match.group(1).strip()\n",
    "                level = int(match.group(2))\n",
    "        else:\n",
    "            # Logic for items (if format is \"Item x64\")\n",
    "            # Actually these are disabled\n",
    "            # This depends on how GTS formats items, assuming simple name for now\n",
    "            pass\n",
    "\n",
    "        return pd.Series([product_name, level, quantity])\n",
    "\n",
    "\n",
    "    print(\"[INFO] Parsing product descriptions...\")\n",
    "    df_final[['product_name', 'level', 'quantity']] = df_final.apply(parse_description, axis=1)\n",
    "\n",
    "    # B. Time to Sell (Hours)\n",
    "    # listingDurationMs tells us how long it sat on the market\n",
    "    if 'listingDurationMs' in df_final.columns:\n",
    "        df_final['hours_on_market'] = df_final['listingDurationMs'] / (1000 * 60 * 60)\n",
    "\n",
    "    # C. Server ID (One-Hot)\n",
    "    if 'server_id' in df_final.columns:\n",
    "        server_dummies = pd.get_dummies(df_final['server_id'], prefix='server')\n",
    "        df_final = pd.concat([df_final, server_dummies], axis=1)\n",
    "\n",
    "    print(\"[+] Feature Engineering complete.\")\n",
    "    display(df_final[['itemType', 'product_name', 'level', 'price', 'hours_on_market']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ANALYSIS & VISUALIZATION\n",
    "\n",
    "if not df_final.empty:\n",
    "    # Filter only Pokemon for clearer graphs\n",
    "    pokemon_sales = df_final[df_final['itemType'] == 'POKEMON']\n",
    "\n",
    "    if not pokemon_sales.empty:\n",
    "        # Graph 1: Top 10 Most Expensive Species (Average)\n",
    "        avg_prices = pokemon_sales.groupby('product_name')['price'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=avg_prices.values, y=avg_prices.index, palette='viridis', hue=avg_prices.index, legend=False)\n",
    "        plt.title('Top 10 Most Expensive Pok√©mon (Avg Price)')\n",
    "        plt.xlabel('Price')\n",
    "        plt.show()\n",
    "\n",
    "        # Graph 2: Price vs Level (Scatter plot)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.scatterplot(x='level', y='price', data=pokemon_sales, hue='product_name', legend=False)\n",
    "        plt.title('Price Correlation with Level')\n",
    "        plt.show()\n",
    "\n",
    "    # Graph 3: Sales Volume by Server\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='server_id', data=df_final, palette='magma', hue='server_id', legend=False)\n",
    "    plt.title('Transactions Volume by Server')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CLEAN DATASET\n",
    "\n",
    "if not df_final.empty:\n",
    "    cols_to_keep = [\n",
    "        'itemType',\n",
    "        'product_name',\n",
    "        'level',\n",
    "        'price',\n",
    "        'hours_on_market',\n",
    "        'sellerUuid',\n",
    "        'buyerUuid',\n",
    "        'world',\n",
    "        'biome'\n",
    "    ]\n",
    "    # Add server columns\n",
    "    cols_to_keep.extend([col for col in df_final.columns if 'server_' in col])\n",
    "\n",
    "    df_export = df_final[cols_to_keep].copy()\n",
    "\n",
    "    df_export.to_csv(CLEAN_DATA_PATH, index=False)\n",
    "    print(f\"[+] Clean economy dataset saved to: {CLEAN_DATA_PATH}\")\n",
    "    display(df_export.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
