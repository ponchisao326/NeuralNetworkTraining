{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Pandas settings for better display in PyCharm\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# CREDENTIALS\n",
    "API_URL = os.getenv(\"API_URL\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "CLEAN_DATA_PATH = \"data/dataset_raids_clean.csv\"\n",
    "\n",
    "print(\"[+] Libs loaded and settings configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_api(action_type):\n",
    "    print(f\"[+] Connecting to {API_URL}...\")\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {API_KEY}\"},\n",
    "            params={\"action\": action_type}\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"[+] Received {len(data)} events.\")\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"[-] API ERROR: {response.status_code} - {response.text}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"[-] Connexion error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "raw_data = get_data_from_api(\"RAID_INTERACTION\")\n",
    "\n",
    "if raw_data:\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(raw_data)\n",
    "\n",
    "    # 'context_data' column cleaning\n",
    "    def clean_json(x):\n",
    "        if isinstance(x, dict): return x\n",
    "        try: return json.loads(x)\n",
    "        except: return {}\n",
    "\n",
    "    df['context_data'] = df['context_data'].apply(clean_json)\n",
    "\n",
    "    # Flatten the 'context_data' JSON column\n",
    "    df_context = pd.json_normalize(df['context_data'])\n",
    "\n",
    "    # Search for duplicated columns between SQL table and JSON\n",
    "    duped_columns = df_context.columns.intersection(df.columns)\n",
    "\n",
    "    # We remove them from the JSON DataFrame because the main table ones are more reliable\n",
    "    if not duped_columns.empty:\n",
    "        print(f\"[INFO] Deleting duped columns from JSON: {list(duped_columns)}\")\n",
    "        df_context = df_context.drop(columns=duped_columns)\n",
    "\n",
    "    # Join and drop original JSON column\n",
    "    df_final = df.join(df_context).drop(columns=['context_data'])\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # CRITICAL FIX: Swap World and Biome columns\n",
    "    # The Java mod sends these inverted for Raids. We fix it here.\n",
    "    # -----------------------------------------------------------\n",
    "    print(\"[INFO] Applying fix for swapped World/Biome columns...\")\n",
    "\n",
    "    # We copy the series to avoid reference issues\n",
    "    real_worlds = df_final['biome'].copy() # Biome column actually contains the World\n",
    "    real_biomes = df_final['world'].copy() # World column actually contains the Biome\n",
    "\n",
    "    df_final['world'] = real_worlds\n",
    "    df_final['biome'] = real_biomes\n",
    "\n",
    "    print(f\"[INFO] Verification -> World: {df_final['world'].iloc[0]} | Biome: {df_final['biome'].iloc[0]}\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # SERVER PROCESSING\n",
    "    # Convert 'xerneas'/'yveltal' strings into One-Hot Encoded columns\n",
    "    # -----------------------------------------------------------\n",
    "    if 'server_id' in df_final.columns:\n",
    "        print(\"[INFO] Processing Server IDs...\")\n",
    "        server_dummies = pd.get_dummies(df_final['server_id'], prefix='server')\n",
    "        # Join the new boolean columns to the main dataframe\n",
    "        df_final = pd.concat([df_final, server_dummies], axis=1)\n",
    "\n",
    "    # Create Target (Objective)\n",
    "    if 'result' in df_final.columns:\n",
    "        df_final['target'] = df_final['result'].apply(lambda x: 1 if x == 'WIN' else 0)\n",
    "\n",
    "    # Filter only useful columns for the AI (Cleanup)\n",
    "    cols_to_keep = [\n",
    "        'target',\n",
    "        'bossSpecies',\n",
    "        'participantsCount',\n",
    "        'damageDealt',\n",
    "        'world',\n",
    "        'biome',\n",
    "        'result' # Kept for visualization in next cell\n",
    "    ]\n",
    "    # Dynamically add the server columns (e.g., server_xerneas)\n",
    "    cols_to_keep.extend([col for col in df_final.columns if 'server_' in col])\n",
    "\n",
    "    # Update df_final to only contain clean data\n",
    "    df_final = df_final[cols_to_keep].copy()\n",
    "\n",
    "    print(\"[+] Data processed and corrected:\")\n",
    "    display(df_final.head())\n",
    "else:\n",
    "    print(\"[-] There is any data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target' in df_final.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Plotting the count of wins and losses\n",
    "    sns.countplot(x='result', hue='result', data=df_final, palette='viridis', legend=False)\n",
    "\n",
    "    plt.title('Raids Balance (Wins vs Losses)')\n",
    "    plt.xlabel('Result')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"[+] Victory Rate: {df_final['target'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data directory exists\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "    print(\"[+] Created 'data' directory.\")\n",
    "\n",
    "if not df_final.empty:\n",
    "    df_final.to_csv(CLEAN_DATA_PATH, index=False)\n",
    "    print(f\"[+] File '{CLEAN_DATA_PATH}' saved correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
